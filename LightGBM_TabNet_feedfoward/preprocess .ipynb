{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moU_CvJ0j1sd",
        "outputId": "4ce587f7-4642-43ad-ebc3-8bf49de14bd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "515W1pcfMoUt"
      },
      "outputs": [],
      "source": [
        "!unzip gdrive/My\\ Drive/optiver-realized-volatility-prediction.zip > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def read_train_test():\n",
        "\n",
        "    data = pd.read_csv('/content/optiver-realized-volatility-prediction/train.csv')\n",
        "\n",
        "    unique_stock_ids = data['stock_id'].unique()\n",
        "    gk = data.groupby('stock_id')\n",
        "\n",
        "    train=pd.DataFrame()\n",
        "    test=pd.DataFrame()\n",
        "    for id in unique_stock_ids:\n",
        "       gkk=gk.get_group(id)\n",
        "       # Creating a dataframe with 70%\n",
        "       # values of original dataframe\n",
        "       train_df = gkk.sample(frac = 0.7)\n",
        "       \n",
        "       # Creating dataframe with\n",
        "       # rest of the 30% values\n",
        "       test_df = gkk.drop(train_df.index)\n",
        " \n",
        "       train=pd.concat([train,train_df])\n",
        "       test=pd.concat([test,test_df])\n",
        "\n",
        "    # Create a key to merge with book and trade data\n",
        "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
        "    test['row_id'] = test['stock_id'].astype(str) + '-' + test['time_id'].astype(str)\n",
        "\n",
        "    return train,test"
      ],
      "metadata": {
        "id": "8iBcJ34ZhHD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUovwfeY0o-S"
      },
      "outputs": [],
      "source": [
        "train,test=read_train_test()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv('train_org.csv', encoding='utf-8', index=False)\n",
        "test.to_csv('test_org.csv', encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "cwVFGvqO50Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "-xatgt9B4DMZ",
        "outputId": "c55bbb46-0956-44cb-f9d1-8ba3b7a40782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        stock_id  time_id    target     row_id\n",
              "2              0       16  0.002168       0-16\n",
              "3              0       31  0.002195       0-31\n",
              "6              0       97  0.009388       0-97\n",
              "7              0      103  0.004120      0-103\n",
              "16             0      169  0.003365      0-169\n",
              "...          ...      ...       ...        ...\n",
              "428923       126    32739  0.002529  126-32739\n",
              "428924       126    32746  0.009973  126-32746\n",
              "428926       126    32750  0.003350  126-32750\n",
              "428927       126    32751  0.003461  126-32751\n",
              "428928       126    32753  0.003113  126-32753\n",
              "\n",
              "[128681 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7afde14-f771-4a99-9d7c-e79f739fe674\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stock_id</th>\n",
              "      <th>time_id</th>\n",
              "      <th>target</th>\n",
              "      <th>row_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0.002168</td>\n",
              "      <td>0-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0.002195</td>\n",
              "      <td>0-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>97</td>\n",
              "      <td>0.009388</td>\n",
              "      <td>0-97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>103</td>\n",
              "      <td>0.004120</td>\n",
              "      <td>0-103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>169</td>\n",
              "      <td>0.003365</td>\n",
              "      <td>0-169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428923</th>\n",
              "      <td>126</td>\n",
              "      <td>32739</td>\n",
              "      <td>0.002529</td>\n",
              "      <td>126-32739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428924</th>\n",
              "      <td>126</td>\n",
              "      <td>32746</td>\n",
              "      <td>0.009973</td>\n",
              "      <td>126-32746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428926</th>\n",
              "      <td>126</td>\n",
              "      <td>32750</td>\n",
              "      <td>0.003350</td>\n",
              "      <td>126-32750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428927</th>\n",
              "      <td>126</td>\n",
              "      <td>32751</td>\n",
              "      <td>0.003461</td>\n",
              "      <td>126-32751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428928</th>\n",
              "      <td>126</td>\n",
              "      <td>32753</td>\n",
              "      <td>0.003113</td>\n",
              "      <td>126-32753</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>128681 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7afde14-f771-4a99-9d7c-e79f739fe674')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7afde14-f771-4a99-9d7c-e79f739fe674 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7afde14-f771-4a99-9d7c-e79f739fe674');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YTaVoDLn39Zh",
        "outputId": "459424a7-b086-4521-9f3c-3910bc943b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        stock_id  time_id    target     row_id\n",
              "2346           0    19386  0.001140    0-19386\n",
              "726            0     5916  0.004280     0-5916\n",
              "630            0     5173  0.005571     0-5173\n",
              "1949           0    16147  0.004431    0-16147\n",
              "261            0     2119  0.003451     0-2119\n",
              "...          ...      ...       ...        ...\n",
              "427348       126    18514  0.005363  126-18514\n",
              "426382       126    10806  0.008255  126-10806\n",
              "428883       126    32330  0.003487  126-32330\n",
              "426480       126    11655  0.006074  126-11655\n",
              "427402       126    18967  0.003555  126-18967\n",
              "\n",
              "[300251 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b623a313-e22d-4bcb-a8db-1b6b1a0755fc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stock_id</th>\n",
              "      <th>time_id</th>\n",
              "      <th>target</th>\n",
              "      <th>row_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2346</th>\n",
              "      <td>0</td>\n",
              "      <td>19386</td>\n",
              "      <td>0.001140</td>\n",
              "      <td>0-19386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>726</th>\n",
              "      <td>0</td>\n",
              "      <td>5916</td>\n",
              "      <td>0.004280</td>\n",
              "      <td>0-5916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630</th>\n",
              "      <td>0</td>\n",
              "      <td>5173</td>\n",
              "      <td>0.005571</td>\n",
              "      <td>0-5173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1949</th>\n",
              "      <td>0</td>\n",
              "      <td>16147</td>\n",
              "      <td>0.004431</td>\n",
              "      <td>0-16147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>0</td>\n",
              "      <td>2119</td>\n",
              "      <td>0.003451</td>\n",
              "      <td>0-2119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427348</th>\n",
              "      <td>126</td>\n",
              "      <td>18514</td>\n",
              "      <td>0.005363</td>\n",
              "      <td>126-18514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426382</th>\n",
              "      <td>126</td>\n",
              "      <td>10806</td>\n",
              "      <td>0.008255</td>\n",
              "      <td>126-10806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428883</th>\n",
              "      <td>126</td>\n",
              "      <td>32330</td>\n",
              "      <td>0.003487</td>\n",
              "      <td>126-32330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426480</th>\n",
              "      <td>126</td>\n",
              "      <td>11655</td>\n",
              "      <td>0.006074</td>\n",
              "      <td>126-11655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427402</th>\n",
              "      <td>126</td>\n",
              "      <td>18967</td>\n",
              "      <td>0.003555</td>\n",
              "      <td>126-18967</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300251 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b623a313-e22d-4bcb-a8db-1b6b1a0755fc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b623a313-e22d-4bcb-a8db-1b6b1a0755fc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b623a313-e22d-4bcb-a8db-1b6b1a0755fc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtJrau3mgQIM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from typing import Any, Dict, List, Tuple\n",
        "#Functions to define weighted average prices\n",
        "def calc_wap1(df):\n",
        "\n",
        "  wap=(df[\"bid_price1\"] * df['ask_size1'] + df[\"ask_price1\"]*df[\"bid_size1\"])/(df['ask_size1']+df['bid_size1'])\n",
        "\n",
        "  return wap\n",
        "\n",
        "def calc_wap2(df):\n",
        "\n",
        "  wap=(df[\"bid_price2\"] * df['ask_size2'] + df[\"ask_price2\"]*df[\"bid_size2\"])/(df['ask_size2']+df['bid_size2'])\n",
        "\n",
        "  return wap\n",
        "\n",
        "def calc_wap3(df):\n",
        "\n",
        "  wap=(df[\"bid_price1\"] * df['bid_size1'] + df[\"ask_price1\"]*df[\"ask_size1\"])/(df['ask_size1']+df['bid_size1'])\n",
        "\n",
        "  return wap\n",
        "\n",
        "def calc_wap4(df):\n",
        "\n",
        "  wap=(df[\"bid_price2\"] * df['bid_size2'] + df[\"ask_price2\"]*df[\"ask_size2\"])/(df['ask_size2']+df['bid_size2'])\n",
        "\n",
        "  return wap\n",
        "\n",
        "def log_return(series):\n",
        "   return np.log(series).diff()\n",
        "\n",
        "def realised_volatility(series):\n",
        "   return np.sqrt(np.sum(series**2)) \n",
        "\n",
        "def count_unique(series):\n",
        "    return len(np.unique(series))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsTe7FXx1Ks_"
      },
      "outputs": [],
      "source": [
        "def book_preprocessor(file_path):\n",
        "   \n",
        "    #print(\"stock_id=\",file_path.split('=')[1])\n",
        "    df = pd.read_parquet(file_path)\n",
        "\n",
        "   #calculating weighted average prices\n",
        "    df['wap1'] = calc_wap1(df)\n",
        "    df['wap2'] = calc_wap2(df)\n",
        "    df['wap3'] = calc_wap3(df)\n",
        "    df['wap4'] = calc_wap4(df)\n",
        "\n",
        "   #calculating log return(stock return) values\n",
        "    df['log_return1']=df.groupby(['time_id'])['wap1'].apply(log_return)\n",
        "    df['log_return2']=df.groupby(['time_id'])['wap2'].apply(log_return)\n",
        "    df['log_return3']=df.groupby(['time_id'])['wap3'].apply(log_return)\n",
        "    df['log_return4']=df.groupby(['time_id'])['wap4'].apply(log_return)\n",
        "   \n",
        "    #calculating wap balance\n",
        "    df['wap_balance']=abs(df['wap1']-df['wap2'])\n",
        "\n",
        "    #calculating differences\n",
        "    df['price_spread1']=(df['ask_price1']-df['bid_price1'])/(df['ask_price1']+df['bid_price1'])\n",
        "    df['price_spread2']=(df['ask_price2']-df['bid_price2'])/(df['ask_price2']+df['bid_price2'])\n",
        "    df['bid_spread']=df['bid_price1']-df['bid_price2']\n",
        "    df['ask_spread']=df['ask_price1']-df['ask_price2']\n",
        "    df['bid_ask_spread']=df['bid_spread']-df['ask_spread']\n",
        "    df['total_volume']=df['bid_size1']+df['bid_size1']+df['ask_size1']+df['ask_size2']\n",
        "    df['volume_imbalance']=abs((df['bid_size1']+df['bid_size1'])-(df['ask_size1']+df['ask_size2']))\n",
        "\n",
        "\n",
        "\n",
        "    #creating dictionary for aggregating the values\n",
        "    feature_dict= {\n",
        "        'wap1':[np.sum,np.std],\n",
        "        'wap2':[np.sum,np.std],\n",
        "        'wap3':[np.sum,np.std],\n",
        "        'wap4':[np.sum,np.std],\n",
        "        'log_return1':[realised_volatility],\n",
        "        'log_return2':[realised_volatility],\n",
        "        'log_return3':[realised_volatility],\n",
        "        'log_return4':[realised_volatility],\n",
        "        'wap_balance':  [np.sum,np.max],\n",
        "        'price_spread1':[np.sum,np.max],\n",
        "        'price_spread2':[np.sum,np.max],\n",
        "        'bid_spread':[np.sum,np.max],\n",
        "        'ask_spread':[np.sum,np.max],\n",
        "        'bid_ask_spread':[np.sum,np.max],\n",
        "        'total_volume':[np.sum,np.max],\n",
        "        'volume_imbalance':[np.sum,np.max]\n",
        "    }\n",
        "\n",
        "    feature_dict_time={\n",
        "        'log_return1':[realised_volatility],\n",
        "        'log_return2':[realised_volatility],\n",
        "        'log_return3':[realised_volatility],\n",
        "        'log_return4':[realised_volatility]\n",
        "    }\n",
        "    \n",
        "    #getting statistics for each group for different windows(seconds_in_bucket)\n",
        "    def get_stats_window(feature_dict,seconds_in_bucket,suffix=False):\n",
        "        df_feature =df[df['seconds_in_bucket']>=seconds_in_bucket].groupby('time_id').agg(feature_dict).reset_index()\n",
        "        #renaming the  columns\n",
        "        df_feature.columns =['_'.join(col) for col in df_feature.columns]\n",
        "        #adding the suffix for differentiating windows\n",
        "        if suffix:\n",
        "          df_feature=df_feature.add_suffix('_'+str(seconds_in_bucket))\n",
        "\n",
        "        return df_feature\n",
        "    \n",
        "\n",
        "    df_feature=get_stats_window(feature_dict,seconds_in_bucket=0,suffix=False)\n",
        "    df_feature_500=get_stats_window(feature_dict_time,seconds_in_bucket=500,suffix=True)\n",
        "    df_feature_400=get_stats_window(feature_dict_time,seconds_in_bucket=400,suffix=True)\n",
        "    df_feature_300=get_stats_window(feature_dict_time,seconds_in_bucket=300,suffix=True)\n",
        "    df_feature_200=get_stats_window(feature_dict_time,seconds_in_bucket=200,suffix=True)\n",
        "    df_feature_100=get_stats_window(feature_dict_time,seconds_in_bucket=100,suffix=True)\n",
        "\n",
        "    #merging \n",
        "    df_feature=df_feature.merge(df_feature_500,how='left',left_on='time_id_',right_on='time_id__500')\n",
        "    df_feature=df_feature.merge(df_feature_400,how='left',left_on='time_id_',right_on='time_id__400')\n",
        "    df_feature=df_feature.merge(df_feature_300,how='left',left_on='time_id_',right_on='time_id__300')\n",
        "    df_feature=df_feature.merge(df_feature_200,how='left',left_on='time_id_',right_on='time_id__200')\n",
        "    df_feature=df_feature.merge(df_feature_100,how='left',left_on='time_id_',right_on='time_id__100')\n",
        "\n",
        "    #dropping unnecessary time_id columns\n",
        "    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id__100'],axis=1,inplace=True)\n",
        "\n",
        "    stock_id = file_path.split('=')[1]\n",
        "    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x: f'{stock_id}-{x}')\n",
        "    df_feature.drop(['time_id_'], axis = 1, inplace = True)\n",
        "    return df_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0tEE8ih1kH3"
      },
      "outputs": [],
      "source": [
        "def trade_preprocessor(file_path):\n",
        "    df = pd.read_parquet(file_path)\n",
        "    #calculating log return(stock return) values\n",
        "    df['log_return']=df.groupby(['time_id'])['price'].apply(log_return)\n",
        "    df['amount']=df['price']*df['size']\n",
        "\n",
        "    #creating dictionaries for aggregating\n",
        "    feature_dict= {\n",
        "            'log_return':[realised_volatility],\n",
        "            'seconds_in_bucket':[count_unique],\n",
        "            'size':[np.sum,np.max,np.min],\n",
        "            'order_count':[np.sum,np.max],\n",
        "            'amount':[np.sum,np.max,np.min]\n",
        "    }\n",
        "\n",
        "    feature_dict_time={\n",
        "        'log_return':[realised_volatility],\n",
        "        'seconds_in_bucket':[count_unique],\n",
        "        'size':[np.sum],\n",
        "        'order_count':[np.sum]\n",
        "    }\n",
        "\n",
        "    #getting statistics for each group for different windows(seconds_in_bucket)\n",
        "    def get_stats_window(feature_dict,seconds_in_bucket,suffix=False):\n",
        "        df_feature =df[df['seconds_in_bucket']>=seconds_in_bucket].groupby('time_id').agg(feature_dict).reset_index()\n",
        "        #renaming the  columns\n",
        "        df_feature.columns =['_'.join(col) for col in df_feature.columns]\n",
        "        #adding the suffix for differentiating windows\n",
        "        if suffix:\n",
        "          df_feature=df_feature.add_suffix('_'+str(seconds_in_bucket))\n",
        "\n",
        "        return df_feature\n",
        "\n",
        "    df_feature=get_stats_window(feature_dict,seconds_in_bucket=0,suffix=False)\n",
        "    df_feature_500=get_stats_window(feature_dict_time,seconds_in_bucket=500,suffix=True)\n",
        "    df_feature_400=get_stats_window(feature_dict_time,seconds_in_bucket=400,suffix=True)\n",
        "    df_feature_300=get_stats_window(feature_dict_time,seconds_in_bucket=300,suffix=True)\n",
        "    df_feature_200=get_stats_window(feature_dict_time,seconds_in_bucket=200,suffix=True)\n",
        "    df_feature_100=get_stats_window(feature_dict_time,seconds_in_bucket=100,suffix=True)\n",
        "     \n",
        "    def tendency(price,vol):\n",
        "       df_diff =np.diff(price)\n",
        "       val = (df_diff/price[1:])*100\n",
        "       power =np.sum(val*vol[1:])      \n",
        "       return power\n",
        "\n",
        "    list_features=[]\n",
        "    for time_id_n in df['time_id'].unique():\n",
        "      df_id=df[df['time_id']== time_id_n]\n",
        "      tendencyV=tendency(df_id['price'].values,df_id['size'].values)\n",
        "      f_max=np.sum(df_id['price'].values > np.mean(df_id['price'].values))\n",
        "      f_min=np.sum(df_id['price'].values < np.mean(df_id['price'].values))\n",
        "      df_max=np.sum(np.diff(df_id['price'].values)>0)\n",
        "      df_min=np.sum(np.diff(df_id['price'].values)<0)\n",
        "\n",
        "      abs_diff_p = np.median(abs(df_id['price'].values - np.mean(df_id['price'].values)))\n",
        "      energy_p=np.mean(df_id['price'].values**2)\n",
        "      inter_quartile_p=np.percentile(df_id['price'].values,75)-np.percentile(df_id['price'].values,25)\n",
        "\n",
        "      abs_diff_v = np.median(abs(df_id['size'].values - np.mean(df_id['size'].values)))\n",
        "      energy_v=np.mean(df_id['size'].values**2)\n",
        "      inter_quartile_v=np.percentile(df_id['size'].values,75)-np.percentile(df_id['size'].values,25)\n",
        "\n",
        "\n",
        "      list_features.append({ 'time_id':time_id_n, 'tendency':tendencyV, 'f_max':f_max,'f_min':f_min,'df_max':df_max,'df_min':df_min,\n",
        "                            'abs_diff_p':abs_diff_p,'energy_p':energy_p,'inter_quartile_p':inter_quartile_p,'abs_diff_v':abs_diff_v,\n",
        "                            'energy_v':energy_v,'inter_quartile_v':inter_quartile_v })\n",
        "      \n",
        "    df_list =pd.DataFrame(list_features)\n",
        "    df_feature=df_feature.merge(df_list,how='left',left_on='time_id_',right_on='time_id')\n",
        "\n",
        "\n",
        "    #merging \n",
        "    df_feature=df_feature.merge(df_feature_500,how='left',left_on='time_id_',right_on='time_id__500')\n",
        "    df_feature=df_feature.merge(df_feature_400,how='left',left_on='time_id_',right_on='time_id__400')\n",
        "    df_feature=df_feature.merge(df_feature_300,how='left',left_on='time_id_',right_on='time_id__300')\n",
        "    df_feature=df_feature.merge(df_feature_200,how='left',left_on='time_id_',right_on='time_id__200')\n",
        "    df_feature=df_feature.merge(df_feature_100,how='left',left_on='time_id_',right_on='time_id__100')\n",
        "\n",
        "    #dropping unnecessary time_id columns\n",
        "    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id__100'],axis=1,inplace=True)\n",
        "\n",
        "    df_feature = df_feature.add_prefix('trade_')\n",
        "    stock_id = file_path.split('=')[1]\n",
        "    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x: f'{stock_id}-{x}')\n",
        "    df_feature.drop(['trade_time_id_'], axis = 1, inplace = True)\n",
        "\n",
        "    return df_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsqaPvSd4v0j"
      },
      "outputs": [],
      "source": [
        "from joblib import Parallel,delayed\n",
        "def preprocessor(list_stock_ids, is_train = True):\n",
        "  # Parrallel for loop\n",
        "    def for_joblib(stock_id):\n",
        "        data_dir='/content/optiver-realized-volatility-prediction/'\n",
        "        book_df_train=pd.DataFrame()\n",
        "        trade_df_train=pd.DataFrame()\n",
        "       \n",
        "        file_path_book = data_dir + \"book_train.parquet/stock_id=\" +str(stock_id)\n",
        "        file_path_trade = data_dir + \"trade_train.parquet/stock_id=\" +str(stock_id)\n",
        "\n",
        "        if(is_train== True):\n",
        "              book_df= book_preprocessor(file_path_book)\n",
        "              trade_df= trade_preprocessor(file_path_trade)\n",
        "              df_tmp = pd.merge(book_df, trade_df, on = 'row_id', how = 'left')\n",
        "        else:\n",
        "              book_df_test= book_preprocessor(file_path_book)\n",
        "              trade_df_test= trade_preprocessor(file_path_trade) \n",
        "              df_tmp = pd.merge(book_df_test, trade_df_test, on = 'row_id', how = 'left')\n",
        "        \n",
        "        return df_tmp\n",
        "\n",
        "\n",
        "    df = Parallel(n_jobs = None, verbose = 1)(delayed(for_joblib)(stock_id)for stock_id in list_stock_ids)\n",
        "    #df= (for_joblib(stock_id) for stock_id in list_stock_ids)\n",
        "\n",
        "    df = pd.concat(df, ignore_index = True)\n",
        "    #print()\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_time_stock(df):\n",
        "    vol_cols = ['log_return1_realised_volatility', 'log_return2_realised_volatility', 'log_return1_realised_volatility_400', 'log_return2_realised_volatility_400', \n",
        "                'log_return1_realised_volatility_300', 'log_return2_realised_volatility_300', 'log_return1_realised_volatility_200', 'log_return2_realised_volatility_200', \n",
        "                'trade_log_return_realised_volatility', 'trade_log_return_realised_volatility_400', 'trade_log_return_realised_volatility_300', 'trade_log_return_realised_volatility_200']\n",
        "\n",
        "\n",
        "    # Group by the stock id\n",
        "    df_stock_id = df.groupby(['stock_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
        "    # Rename columns joining suffix\n",
        "    df_stock_id.columns = ['_'.join(col) for col in df_stock_id.columns]\n",
        "    df_stock_id = df_stock_id.add_suffix('_' + 'stock')\n",
        "\n",
        "    # Group by the stock id\n",
        "    df_time_id = df.groupby(['time_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
        "    # Rename columns joining suffix\n",
        "    df_time_id.columns = ['_'.join(col) for col in df_time_id.columns]\n",
        "    df_time_id = df_time_id.add_suffix('_' + 'time')\n",
        "    \n",
        "    # Merge with original dataframe\n",
        "    df = df.merge(df_stock_id, how = 'left', left_on = ['stock_id'], right_on = ['stock_id__stock'])\n",
        "    df = df.merge(df_time_id, how = 'left', left_on = ['time_id'], right_on = ['time_id__time'])\n",
        "    df.drop(['stock_id__stock', 'time_id__time'], axis = 1, inplace = True)\n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "V96vrEG2-ptU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# replace by order sum (tau)\n",
        "def add_tau_feature(\n",
        "    train: pd.DataFrame, test: pd.DataFrame\n",
        ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    train[\"size_tau\"] = np.sqrt(1 / train[\"trade_seconds_in_bucket_count_unique\"])\n",
        "    test[\"size_tau\"] = np.sqrt(1 / test[\"trade_seconds_in_bucket_count_unique\"])\n",
        "    # train['size_tau_450'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_450'] )\n",
        "    # test['size_tau_450'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_450'] )\n",
        "    train[\"size_tau_400\"] = np.sqrt(\n",
        "        1 / train[\"trade_seconds_in_bucket_count_unique_400\"]\n",
        "    )\n",
        "    test[\"size_tau_400\"] = np.sqrt(1 / test[\"trade_seconds_in_bucket_count_unique_400\"])\n",
        "    train[\"size_tau_300\"] = np.sqrt(\n",
        "        1 / train[\"trade_seconds_in_bucket_count_unique_300\"]\n",
        "    )\n",
        "    test[\"size_tau_300\"] = np.sqrt(1 / test[\"trade_seconds_in_bucket_count_unique_300\"])\n",
        "    # train['size_tau_150'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_150'] )\n",
        "    # test['size_tau_150'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_150'] )\n",
        "    train[\"size_tau_200\"] = np.sqrt(\n",
        "        1 / train[\"trade_seconds_in_bucket_count_unique_200\"]\n",
        "    )\n",
        "    test[\"size_tau_200\"] = np.sqrt(1 / test[\"trade_seconds_in_bucket_count_unique_200\"])\n",
        "    train[\"size_tau2\"] = np.sqrt(1 / train[\"trade_order_count_sum\"])\n",
        "    test[\"size_tau2\"] = np.sqrt(1 / test[\"trade_order_count_sum\"])\n",
        "    # train['size_tau2_450'] = np.sqrt( 0.25/ train['trade_order_count_sum'] )\n",
        "    # test['size_tau2_450'] = np.sqrt( 0.25/ test['trade_order_count_sum'] )\n",
        "    train[\"size_tau2_400\"] = np.sqrt(0.33 / train[\"trade_order_count_sum\"])\n",
        "    test[\"size_tau2_400\"] = np.sqrt(0.33 / test[\"trade_order_count_sum\"])\n",
        "    train[\"size_tau2_300\"] = np.sqrt(0.5 / train[\"trade_order_count_sum\"])\n",
        "    test[\"size_tau2_300\"] = np.sqrt(0.5 / test[\"trade_order_count_sum\"])\n",
        "    # train['size_tau2_150'] = np.sqrt( 0.75/ train['trade_order_count_sum'] )\n",
        "    # test['size_tau2_150'] = np.sqrt( 0.75/ test['trade_order_count_sum'] )\n",
        "    train[\"size_tau2_200\"] = np.sqrt(0.66 / train[\"trade_order_count_sum\"])\n",
        "    test[\"size_tau2_200\"] = np.sqrt(0.66 / test[\"trade_order_count_sum\"])\n",
        "\n",
        "    # delta tau\n",
        "    train[\"size_tau2_d\"] = train[\"size_tau2_400\"] - train[\"size_tau2\"]\n",
        "    test[\"size_tau2_d\"] = test[\"size_tau2_400\"] - test[\"size_tau2\"]\n",
        "\n",
        "    return train, test"
      ],
      "metadata": {
        "id": "MO-k-GtYCYwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from tqdm import tqdm\n",
        "def create_agg_features(\n",
        "    train: pd.DataFrame, test: pd.DataFrame, train_p:pd.DataFrame\n",
        ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    # Making agg features\n",
        "    #train_p = pd.read_csv(path + \"train.csv\")\n",
        "    train_p = train_p.pivot(index=\"time_id\", columns=\"stock_id\", values=\"target\")\n",
        "    corr = train_p.corr()\n",
        "    ids = corr.index\n",
        "    kmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n",
        "    indexes = [\n",
        "        [(x - 1) for x in ((ids + 1) * (kmeans.labels_ == n)) if x > 0]\n",
        "        for n in tqdm(range(7))\n",
        "    ]\n",
        "   \n",
        "    mat = []\n",
        "    mat_test = []\n",
        "    n = 0\n",
        "    for ind in tqdm(indexes):\n",
        "        new_df = train.loc[train[\"stock_id\"].isin(ind)]\n",
        "        new_df = new_df.groupby([\"time_id\"]).agg(np.nanmean)\n",
        "        new_df.loc[:, \"stock_id\"] = str(n) + \"c1\"\n",
        "        mat.append(new_df)\n",
        "        new_df = test.loc[test[\"stock_id\"].isin(ind)]\n",
        "        new_df = new_df.groupby([\"time_id\"]).agg(np.nanmean)\n",
        "        new_df.loc[:, \"stock_id\"] = str(n) + \"c1\"\n",
        "        mat_test.append(new_df)\n",
        "        n += 1\n",
        "\n",
        "    mat1 = pd.concat(mat).reset_index()\n",
        "    mat1.drop(columns=[\"target\"], inplace=True)\n",
        "\n",
        "    mat2 = pd.concat(mat_test).reset_index()\n",
        "    #mat2 = pd.concat([mat2, mat1.loc[mat1.time_id == 5]])\n",
        "\n",
        "    mat1 = mat1.pivot(index=\"time_id\", columns=\"stock_id\")\n",
        "    mat1.columns = [\"_\".join(x) for x in tqdm(mat1.columns.tolist())]\n",
        "    mat1.reset_index(inplace=True)\n",
        "\n",
        "    mat2 = mat2.pivot(index=\"time_id\", columns=\"stock_id\")\n",
        "    mat2.columns = [\"_\".join(x) for x in tqdm(mat2.columns.tolist())]\n",
        "    mat2.reset_index(inplace=True)\n",
        "    prefix = [\n",
        "        \"log_return1_realised_volatility\",\n",
        "        \"total_volume_sum\",\n",
        "        \"trade_size_sum\",\n",
        "        \"trade_order_count_sum\",\n",
        "        \"price_spread_sum\",\n",
        "        \"bid_spread_sum\",\n",
        "        \"ask_spread_sum\",\n",
        "        \"volume_imbalance_sum\",\n",
        "        \"bid_ask_spread_sum\",\n",
        "        \"size_tau2\",\n",
        "    ]\n",
        "    selected_cols = mat1.filter(\n",
        "        regex=\"|\".join(f\"^{x}.(0|1|3|4|6)c1\" for x in tqdm(prefix))\n",
        "    ).columns.tolist()\n",
        "    selected_cols.append(\"time_id\")\n",
        "    train_m = pd.merge(train, mat1[selected_cols], how=\"left\", on=\"time_id\")\n",
        "    test_m = pd.merge(test, mat2[selected_cols], how=\"left\", on=\"time_id\")\n",
        "\n",
        "    # filling missing values with train means\n",
        "    features = [\n",
        "        col\n",
        "        for col in train_m.columns.tolist()\n",
        "        if col not in [\"time_id\", \"target\", \"row_id\"]\n",
        "    ]\n",
        "\n",
        "    train_m[features] = train_m[features].fillna(train_m[features].mean())\n",
        "    test_m[features] = test_m[features].fillna(train_m[features].mean())\n",
        "\n",
        "    return train_m, test_m"
      ],
      "metadata": {
        "id": "BU0xUyn9CfNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD6FXkfK1p_j"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "\n",
        "def agg_features():\n",
        "    train,test=read_train_test()\n",
        "    train_p=train\n",
        "    # Get unique stock ids \n",
        "    train_stock_ids = train['stock_id'].unique()\n",
        "    print(train_stock_ids)\n",
        "    # Preprocess them using Parallel and our single stock id functions\n",
        "    train_df=  preprocessor(train_stock_ids, is_train = True)\n",
        "    train =  train.merge(train_df, on = ['row_id'], how = 'left')\n",
        "    train =get_time_stock(train)\n",
        "\n",
        "    # Get unique stock ids \n",
        "    #test_stock_ids = test['stock_id'].unique()\n",
        "    # Preprocess them using Parallel and our single stock id functions\n",
        "    #test_df = preprocessor(test_stock_ids, is_train = False)\n",
        "    test = test.merge(train_df, on = ['row_id'], how = 'left')\n",
        "    test=get_time_stock(test)\n",
        "\n",
        "    print(f\"Before Train Features: {train.shape}\")\n",
        "    print(f\"Before Test Features: {test.shape}\")\n",
        "    train, test = add_tau_feature(train, test)\n",
        "    print(f\"Before Train Features: {train.shape}\")\n",
        "    print(f\"Before Test Features: {test.shape}\")\n",
        "    train, test = create_agg_features(train, test, train_p)\n",
        "    print(f\"After Train Features: {train.shape}\")\n",
        "    print(f\"After Test Features: {test.shape}\")\n",
        "    \n",
        "    return train,test,train_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train,test,df_total = agg_features()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N97krgkdibQc",
        "outputId": "2c9760d8-3b7a-425a-c04d-78bb339cbc95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   1   2   3   4   5   6   7   8   9  10  11  13  14  15  16  17  18\n",
            "  19  20  21  22  23  26  27  28  29  30  31  32  33  34  35  36  37  38\n",
            "  39  40  41  42  43  44  46  47  48  50  51  52  53  55  56  58  59  60\n",
            "  61  62  63  64  66  67  68  69  70  72  73  74  75  76  77  78  80  81\n",
            "  82  83  84  85  86  87  88  89  90  93  94  95  96  97  98  99 100 101\n",
            " 102 103 104 105 107 108 109 110 111 112 113 114 115 116 118 119 120 122\n",
            " 123 124 125 126]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 112 out of 112 | elapsed: 54.9min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Train Features: (300251, 190)\n",
            "Before Test Features: (128681, 190)\n",
            "Before Train Features: (300251, 199)\n",
            "Before Test Features: (128681, 199)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 1774.13it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.75it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1365/1365 [00:00<00:00, 1187559.63it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1372/1372 [00:00<00:00, 900843.00it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 107546.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Train Features: (300251, 244)\n",
            "After Test Features: (128681, 244)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv('train_final.csv', encoding='utf-8', index=False)\n",
        "test.to_csv('test_final.csv', encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "YMH4c5qGnXYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length=test.shape"
      ],
      "metadata": {
        "id": "ayQFLyyBxRIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etiIR3M6xfoB",
        "outputId": "26975963-5c74-4888-b86f-a19b4c018bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128681"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train1=train[:length[0]]"
      ],
      "metadata": {
        "id": "xVH_4KcHwN43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train2=train[length[0]:2*length[0]]"
      ],
      "metadata": {
        "id": "D-kz-1fNxMQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a2VMPItkyEw8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}